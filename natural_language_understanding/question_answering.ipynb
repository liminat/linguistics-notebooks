
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Question Answering with BERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pre-trained language representations have been shown to improve many downstream NLP tasks such as question answering, and natural language inference. Devlin, Jacob, et al proposed BERT [1] (Bidirectional Encoder Representations from Transformers), which fine-tunes deep bidirectional representations on a wide range of tasks with minimal task-specific parameters, and obtained state- of-the-art results.\n",
    "\n",
    "In this tutorial, we will focus on adapting the BERT model for the question answering task on the SQuAD dataset. Specifically, we will:\n",
    "\n",
    "- understand how to pre-process the SQuAD dataset to leverage the learnt representation in BERT,\n",
    "- adapt the BERT model to the question answering task, and\n",
    "- load a trained model to perform inference on the SQuAD dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Load MXNet and GluonNLP\n",
    "\n",
    "We first import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.416134Z",
     "start_time": "2019-06-14T01:45:26.339759Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import collections, time, logging\n",
    "import numpy as np\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "import bert\n",
    "import qa_utils\n",
    "from bert.bert_qa_evaluate import PredResult, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspect the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then we take a look at the Stanford Question Answering Dataset (SQuAD). The dataset can be downloaded using the `nlp.data.SQuAD` API. In this tutorial, we create a small dataset with 3 samples from the SQuAD dataset for demonstration purpose.\n",
    "\n",
    "The question answering task on the SQuAD dataset is setup the following way. For each sample in the dataset, a context is provided. The context is usually a long paragraph which contains lots of information. Then a question asked based on the context. The goal is to find the text span in the context that answers the question in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.555133Z",
     "start_time": "2019-06-14T01:45:27.418706Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/datasets/squad/dev-v1.1.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/squad/dev-v1.1.zip...\n",
      "Number of samples in the created dataset subsampled from SQuAD = 3\n"
     ]
    }
   ],
   "source": [
    "full_data = nlp.data.SQuAD(segment='dev', version='1.1')\n",
    "# loading a subset of the dev set of SQuAD\n",
    "num_target_samples = 3\n",
    "target_samples = [full_data[i] for i in range(num_target_samples)]\n",
    "dataset = mx.gluon.data.SimpleDataset(target_samples)\n",
    "print('Number of samples in the created dataset subsampled from SQuAD = %d'%len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's take a look at a sample from the dataset. In this sample, the question is about the location of the game, with a description about the Super Bowl 50 game as the context. Note that three different answer spans are correct for this question, and they start from index 403, 355 and 355 in the context respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.560564Z",
     "start_time": "2019-06-14T01:45:27.557274Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context:\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[2]\n",
    "\n",
    "context_idx = 3\n",
    "\n",
    "print('\\nContext:')\n",
    "print(sample[context_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.567303Z",
     "start_time": "2019-06-14T01:45:27.562425Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question\n",
      "Where did Super Bowl 50 take place?\n",
      "\n",
      "Correct Answer Spans\n",
      "['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"]\n",
      "\n",
      "Answer Span Start Indices:\n",
      "[403, 355, 355]\n"
     ]
    }
   ],
   "source": [
    "question_idx = 2\n",
    "answer_idx = 4\n",
    "answer_pos_idx = 5\n",
    "\n",
    "print(\"\\nQuestion\")\n",
    "print(sample[question_idx])\n",
    "print(\"\\nCorrect Answer Spans\")\n",
    "print(sample[answer_idx])\n",
    "print(\"\\nAnswer Span Start Indices:\")\n",
    "print(sample[answer_pos_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Pre-processing for QA with BERT\n",
    "\n",
    "Recall that during BERT pre-training, it takes a sentence pair as the input, separated by the 'SEP' special token. For SQuAD, we can feed the context-question pair as the sentence pair input. To use BERT to predict the starting and ending span of the answer, we can add a classification layer for each token in the context texts, to predict if a token is the start or the end of the answer span. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:30:12.299493Z",
     "start_time": "2019-06-14T01:30:12.183419Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![qa](qa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the next few code blocks, we will work on pre-processing the samples in the SQuAD dataset in the desired format with these special separators. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, let's use the *get_model* API in GluonNLP to get the model definition for BERT, and the vocabulary used for the BERT model. Note that we discard the pooler and classifier layers used for the next sentence prediction task, as well as the decoder layers for the masked language model task during the BERT pre-training phase. These layers are not useful for predicting the starting and ending indices of the answer span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.715444Z",
     "start_time": "2019-06-14T01:45:27.569118Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /home/ec2-user/.mxnet/models/1562130897.3626611book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n"
     ]
    }
   ],
   "source": [
    "bert_model, vocab = nlp.model.get_model('bert_12_768_12',\n",
    "                                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                        use_classifier=False,\n",
    "                                        use_decoder=False,\n",
    "                                        use_pooler=False,\n",
    "                                        pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that there are several special tokens in the vocabulary for BERT. In particular, the `[SEP]` token is used for separating the sentence pairs, and the `[CLS]` token is added at the beginning of the sentence pairs. They will be used to pre-process the SQuAD dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.720137Z",
     "start_time": "2019-06-14T01:45:27.717192Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The second step is to process the samples using the same tokenizer used for BERT, which is provided as the `BERTTokenizer` API in GluonNLP. Note that instead of word level and character level representation, BERT uses subwords to represent a word, separated `##`. \n",
    "\n",
    "In the following example, the word `suspending` is tokenized as two subwords (`suspend` and `##ing`), and `numerals` is tokenized as three subwords (`nu`, `##meral`, `##s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.731724Z",
     "start_time": "2019-06-14T01:45:27.721690Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'temporarily',\n",
       " 'suspend',\n",
       " '##ing',\n",
       " 'the',\n",
       " 'tradition',\n",
       " 'of',\n",
       " 'naming',\n",
       " 'each',\n",
       " 'super',\n",
       " 'bowl',\n",
       " 'game',\n",
       " 'with',\n",
       " 'roman',\n",
       " 'nu',\n",
       " '##meral',\n",
       " '##s']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nlp.data.BERTTokenizer(vocab=vocab, lower=True)\n",
    "\n",
    "tokenizer(\"as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentence Pair Composition\n",
    "\n",
    "With the tokenizer inplace, we are ready to process the question-context texts and compose sentence pairs. The functionality is available via the `SQuADTransform` API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.897684Z",
     "start_time": "2019-06-14T01:45:27.734029Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Transform dataset costs 0.15 seconds.\n"
     ]
    }
   ],
   "source": [
    "transform = bert.data.qa.SQuADTransform(tokenizer, is_pad=False, is_training=False, do_lookup=False)\n",
    "dev_data_transform, _ = bert.data.qa.preprocess_dataset(dataset, transform)\n",
    "logging.info('The number of examples after preprocessing:{}'.format(len(dev_data_transform)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the sample after the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.904353Z",
     "start_time": "2019-06-14T01:45:27.899992Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "segment type: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "text length: 168\n",
      "\n",
      "sentence pair: ['[CLS]', 'where', 'did', 'super', 'bowl', '50', 'take', 'place', '?', '[SEP]', 'super', 'bowl', '50', 'was', 'an', 'american', 'football', 'game', 'to', 'determine', 'the', 'champion', 'of', 'the', 'national', 'football', 'league', '(', 'nfl', ')', 'for', 'the', '2015', 'season', '.', 'the', 'american', 'football', 'conference', '(', 'afc', ')', 'champion', 'denver', 'broncos', 'defeated', 'the', 'national', 'football', 'conference', '(', 'nfc', ')', 'champion', 'carolina', 'panthers', '24', 'â€“', '10', 'to', 'earn', 'their', 'third', 'super', 'bowl', 'title', '.', 'the', 'game', 'was', 'played', 'on', 'february', '7', ',', '2016', ',', 'at', 'levi', \"'\", 's', 'stadium', 'in', 'the', 'san', 'francisco', 'bay', 'area', 'at', 'santa', 'clara', ',', 'california', '.', 'as', 'this', 'was', 'the', '50th', 'super', 'bowl', ',', 'the', 'league', 'emphasized', 'the', '\"', 'golden', 'anniversary', '\"', 'with', 'various', 'gold', '-', 'themed', 'initiatives', ',', 'as', 'well', 'as', 'temporarily', 'suspend', '##ing', 'the', 'tradition', 'of', 'naming', 'each', 'super', 'bowl', 'game', 'with', 'roman', 'nu', '##meral', '##s', '(', 'under', 'which', 'the', 'game', 'would', 'have', 'been', 'known', 'as', '\"', 'super', 'bowl', 'l', '\"', ')', ',', 'so', 'that', 'the', 'logo', 'could', 'prominently', 'feature', 'the', 'arabic', 'nu', '##meral', '##s', '50', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sample = dev_data_transform[2]\n",
    "print('\\nsegment type: ' + str(sample[2]))\n",
    "print('\\ntext length: ' + str(sample[3]))\n",
    "print('\\nsentence pair: ' + str(sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vocabulary Lookup\n",
    "\n",
    "Finally, we convert the transformed texts to subword indices, which are used to contructor NDArrays as the inputs to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.910853Z",
     "start_time": "2019-06-14T01:45:27.906127Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2073, 2106, 3565, 4605, 2753, 2202, 2173, 1029, 3, 3565, 4605, 2753, 2001, 2019, 2137, 2374, 2208, 2000, 5646, 1996, 3410, 1997, 1996, 2120, 2374, 2223, 1006, 5088, 1007, 2005, 1996, 2325, 2161, 1012, 1996, 2137, 2374, 3034, 1006, 10511, 1007, 3410, 7573, 14169, 3249, 1996, 2120, 2374, 3034, 1006, 22309, 1007, 3410, 3792, 12915, 2484, 1516, 2184, 2000, 7796, 2037, 2353, 3565, 4605, 2516, 1012, 1996, 2208, 2001, 2209, 2006, 2337, 1021, 1010, 2355, 1010, 2012, 11902, 1005, 1055, 3346, 1999, 1996, 2624, 3799, 3016, 2181, 2012, 4203, 10254, 1010, 2662, 1012, 2004, 2023, 2001, 1996, 12951, 3565, 4605, 1010, 1996, 2223, 13155, 1996, 1000, 3585, 5315, 1000, 2007, 2536, 2751, 1011, 11773, 11107, 1010, 2004, 2092, 2004, 8184, 28324, 2075, 1996, 4535, 1997, 10324, 2169, 3565, 4605, 2208, 2007, 3142, 16371, 28990, 2015, 1006, 2104, 2029, 1996, 2208, 2052, 2031, 2042, 2124, 2004, 1000, 3565, 4605, 1048, 1000, 1007, 1010, 2061, 2008, 1996, 8154, 2071, 14500, 3444, 1996, 5640, 16371, 28990, 2015, 2753, 1012, 3]\n"
     ]
    }
   ],
   "source": [
    "def vocab_lookup(example_id, subwords, type_ids, length, start, end):\n",
    "    indices = vocab[subwords]\n",
    "    return example_id, indices, type_ids, length, start, end\n",
    "\n",
    "dev_data_transform = dev_data_transform.transform(vocab_lookup, lazy=False)\n",
    "print(dev_data_transform[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "After the data is processed, we can define the model that uses the representation produced by BERT for predicting the starting and ending positions of the answer span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.921076Z",
     "start_time": "2019-06-14T01:45:27.912650Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class BertForQA(mx.gluon.Block):\n",
    "    \"\"\"Model for SQuAD task with BERT.\n",
    "\n",
    "    The model feeds token ids and token type ids into BERT to get the\n",
    "    pooled BERT sequence representation, then apply a Dense layer for QA task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert: BERTModel\n",
    "        Bidirectional encoder with transformer.\n",
    "    prefix : str or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    params : ParameterDict or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert, prefix=None, params=None):\n",
    "        super(BertForQA, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.span_classifier = mx.gluon.nn.Dense(units=2, flatten=False)\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Generate the unnormalized score for the given the input sequences.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : NDArray, shape (batch_size, seq_length)\n",
    "            Input words for the sequences.\n",
    "        token_types : NDArray, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one.\n",
    "        valid_length : NDArray or None, shape (batch_size,)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : NDArray\n",
    "            Shape (batch_size, seq_length, 2)\n",
    "        \"\"\"\n",
    "        batch_size = inputs.shape[0]\n",
    "        seq_len = inputs.shape[1]\n",
    "        # Use self.bert to get the representation for each token.\n",
    "        bert_output = self.bert(inputs, token_types, valid_length)\n",
    "        assert bert_output.shape == (batch_size, seq_len, 768)\n",
    "        \n",
    "        # Use self.span_classifier to predict the start and end spans\n",
    "        # output = self.span_classifier(...)\n",
    "        output = self.span_classifier(bert_output)\n",
    "        assert output.shape == (batch_size, seq_len, 2)\n",
    "\n",
    "        # Use mx.nd.split to split the prediction of start and end spans\n",
    "        # pred_start, pred_end = mx.nd.split(...)\n",
    "        pred_start, pred_end = mx.nd.split(output, axis=2, num_outputs=2)\n",
    "        assert pred_start.shape == (batch_size, seq_len, 1)\n",
    "        assert pred_end.shape == (batch_size, seq_len, 1)\n",
    "        \n",
    "        return pred_start, pred_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We download a BERT model trained on the SQuAD dataset, prepare the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.221383Z",
     "start_time": "2019-06-14T01:45:27.922825Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ./temp/bert_qa-7eb11865.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_qa-7eb11865.zip...\n",
      "Downloaded checkpoint to ./temp/bert_qa-7eb11865.params\n"
     ]
    }
   ],
   "source": [
    "net = BertForQA(bert_model)\n",
    "ctx = mx.gpu()\n",
    "ckpt = qa_utils.download_qa_ckpt()\n",
    "net.load_parameters(ckpt, ctx=ctx)\n",
    "\n",
    "batch_size = 1\n",
    "dev_dataloader = mx.gluon.data.DataLoader(\n",
    "    dev_data_transform, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.575976Z",
     "start_time": "2019-06-14T01:45:32.223336Z"
    }
   },
   "outputs": [],
   "source": [
    "all_results = collections.defaultdict(list)\n",
    "\n",
    "total_num = 0\n",
    "for data in dev_dataloader:\n",
    "    example_ids, inputs, token_types, valid_length, _, _ = data\n",
    "    total_num += len(inputs)\n",
    "    batch_size = inputs.shape[0]\n",
    "    pred_start, pred_end = net(inputs.astype('float32').as_in_context(ctx),\n",
    "                               token_types.astype('float32').as_in_context(ctx),\n",
    "                               valid_length.astype('float32').as_in_context(ctx))\n",
    "\n",
    "    example_ids = example_ids.asnumpy().tolist()\n",
    "    pred_start = pred_start.reshape(batch_size, -1).asnumpy()\n",
    "    pred_end = pred_end.reshape(batch_size, -1).asnumpy()\n",
    "    \n",
    "    for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "        all_results[example_id].append(PredResult(start=start, end=end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:32.623482Z",
     "start_time": "2019-06-14T01:45:32.578002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question: which nfl team represented the afc at super bowl 50 ?\n",
      "\n",
      "Top predictions: \n",
      "99.36% \t Denver Broncos\n",
      "0.23% \t The American Football Conference (AFC) champion Denver Broncos\n",
      "0.20% \t Broncos\n",
      "\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question: which nfl team represented the nfc at super bowl 50 ?\n",
      "\n",
      "Top predictions: \n",
      "66.65% \t Carolina Panthers\n",
      "24.30% \t Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers\n",
      "7.42% \t Denver Broncos\n",
      "\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question: where did super bowl 50 take place ?\n",
      "\n",
      "Top predictions: \n",
      "25.86% \t Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\n",
      "23.11% \t Levi's Stadium\n",
      "17.88% \t San Francisco Bay Area at Santa Clara, California\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_utils.predict(dataset, all_results, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}