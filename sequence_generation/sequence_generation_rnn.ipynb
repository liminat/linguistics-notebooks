{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Generation with Sampling and Beam Search\n",
    "\n",
    "This tutorial demonstrates how to sample sequences using a\n",
    "pre-trained language model in the following two ways:\n",
    "\n",
    "- with beam search\n",
    "sampler, and\n",
    "- with sequence sampler\n",
    "\n",
    "Let's use `V` to denote the vocabulary size, and `T` to denote the sequence\n",
    "length. Given a language model, we can sample sequences according to the\n",
    "probability that they would occur according to our model. At each time step, a\n",
    "language model predicts the likelihood of each word occurring, given the context\n",
    "from prior time steps. The outputs at any time step can be any word from the\n",
    "vocabulary whose size is V and thus the number of all possible outcomes for a\n",
    "sequence of length T is thus V^T.\n",
    "\n",
    "While sometimes we might want to sample\n",
    "sentences according to their probability of occurring, at other times we want to\n",
    "find the sentences that *are most likely to occur*. This is especially true in\n",
    "the case of language translation where we don't just want to see *a*\n",
    "translation. We want the *best* translation. While finding the optimal outcome\n",
    "quickly becomes intractable as time step increases, there are still many ways to\n",
    "sample reasonably good sequences. GluonNLP provides two samplers for generating\n",
    "from a language model: `